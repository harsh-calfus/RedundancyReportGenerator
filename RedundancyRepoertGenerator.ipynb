{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62378526",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import os\n",
    "import re\n",
    "import time \n",
    "import warnings\n",
    "from collections import defaultdict\n",
    "\n",
    "import google.generativeai as genai\n",
    "import numpy as np\n",
    "import openpyxl\n",
    "import pandas as pd\n",
    "import pycountry\n",
    "import spacy\n",
    "from docx import Document\n",
    "from openpyxl import Workbook\n",
    "from openpyxl.styles import Font\n",
    "from openpyxl.utils.dataframe import dataframe_to_rows\n",
    "from rapidfuzz import fuzz\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from sentence_transformers.util import cos_sim\n",
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a45bf6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YEU\n",
    "# input_path = \"content/YEU_CUST_MSTR.xlsx\"\n",
    "# sheet_name = \"Sheet\"\n",
    "\n",
    "# MITER\n",
    "input_path = \"content/Site and Site Uses.xlsx\"\n",
    "sheet_name = \"Sheet1\"\n",
    "\n",
    "# demo\n",
    "# input_path = \"content/customer_data.xlsx\"\n",
    "# sheet_name = \"Sheet1\"\n",
    "\n",
    "module = \"absolute address\"\n",
    "header_row_num = 0\n",
    "\n",
    "iterations     = 3\n",
    "avg_threshold  = 95.0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ac1198",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Address Line 1',\n",
       " 'Address Line 2',\n",
       " 'Mail Stop',\n",
       " 'City',\n",
       " 'State/Province',\n",
       " 'Postal Code',\n",
       " 'County',\n",
       " 'Country']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genai.configure(api_key=\"AIzaSyA5NWnp7qoQMoTQZMi8cWlS0Ei8-_SDvLs\")\n",
    "model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
    "\n",
    "df = pd.read_excel(input_path, sheet_name)\n",
    "all_columns = pd.read_excel(input_path, sheet_name, header=None).iloc[header_row_num].tolist()\n",
    "\n",
    "prompt = f\"\"\"\n",
    "You are a data expert. Your task is to identify ONLY DISTINGUIHING columns related to module: {module} from a list of column names.\n",
    "\n",
    "Given the following list of column names:\n",
    "{all_columns}\n",
    "\n",
    "Only return a valid Python list of strings. Dont include IDs and Attributes and Timezone. Do not include any explanation or extra text.\n",
    "\n",
    "Example output:\n",
    "[\"module related Column A\", \"module related Column B\", \"module related Column C\", ...]\n",
    "\n",
    "Do not include any explanation or extra text.\n",
    "\"\"\"\n",
    "\n",
    "max_retries = 5\n",
    "address_cols = []\n",
    "\n",
    "for attempt in range(max_retries):\n",
    "    response = model.generate_content(prompt)\n",
    "    text = response.text.strip()\n",
    "\n",
    "    try:\n",
    "        address_cols = ast.literal_eval(text)\n",
    "        if isinstance(address_cols, list) and all(isinstance(col, str) for col in address_cols):\n",
    "            break\n",
    "    except (SyntaxError, ValueError) as e:\n",
    "        print(f\"Attempt {attempt+1} failed:\", e)\n",
    "        print(\"Response was:\", text)\n",
    "        time.sleep(1)\n",
    "\n",
    "address_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e8e1bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "report_cols = [\n",
    "    # Unique Identifiers\n",
    "    'Site ID', 'Site Name', 'Site Purpose',\n",
    "    # Address related columns\n",
    "    'Address Line 1', 'Address Line 2', 'Mail Stop', 'City', 'State/Province',\n",
    "    'Postal Code', 'County', 'Country', \n",
    "    # Business use case related columns (Attributes)\n",
    "    'Site Use Attribute 1', 'Site Use Attribute 2', 'Site Use Attribute 3',\n",
    "    'Site Use Attribute 6', 'Site Use Attribute 7', 'Site Use Attribute 9',\n",
    "    'Site Use Attribute 10'\n",
    "]\n",
    "\n",
    "df = df[report_cols]\n",
    "f = lambda v: ', '.join(sorted(set(str(x) for x in v if pd.notna(x) and str(x).strip())))\n",
    "df = df.groupby(\"Site ID\", as_index=False).agg(lambda col: f(col) if col.name == \"Site Purpose\" else col.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db9a202a",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.system(\"python -m spacy download en_core_web_sm\")\n",
    "sbert = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def normalize_text(s):\n",
    "    s = str(s).lower()\n",
    "    s = re.sub(r\"[^\\w\\s]\", \" \", s)\n",
    "    return re.sub(r\"\\s+\", \" \", s).strip()\n",
    "\n",
    "# full_rows = (\n",
    "#     df[address_cols]\n",
    "#     .fillna(\"\")\n",
    "#     .astype(str)\n",
    "#     .agg(\" \".join, axis=1)\n",
    "#     .map(normalize_text)\n",
    "#     .tolist()\n",
    "# )\n",
    "\n",
    "def build_weighted_text(row):\n",
    "    parts = []\n",
    "    for col in address_cols:\n",
    "        val = str(row.get(col, '')).strip()\n",
    "        if col in [\"Address Line 1\", \"Postal Code\"]:\n",
    "            parts.append((val + \" \") * 3)\n",
    "        else:\n",
    "            parts.append(val)\n",
    "    return normalize_text(\" \".join(parts))\n",
    "\n",
    "full_rows = df[address_cols].apply(build_weighted_text, axis=1).tolist()\n",
    "\n",
    "\n",
    "embs = sbert.encode(full_rows, convert_to_tensor=True, normalize_embeddings=True)\n",
    "matrix = embs.cpu().numpy()\n",
    "\n",
    "# cl = DBSCAN(eps=0.05, min_samples=2, metric='cosine').fit(matrix)\n",
    "cl = DBSCAN(eps=0.1, min_samples=2, metric='cosine').fit(matrix)\n",
    "# cl = DBSCAN(eps=0.15, min_samples=2, metric='cosine').fit(matrix)\n",
    "# cl = DBSCAN(eps=0.20, min_samples=2, metric='cosine').fit(matrix)\n",
    "clusters = defaultdict(list)\n",
    "for idx, label in enumerate(cl.labels_):\n",
    "    if label != -1:\n",
    "        clusters[label].append(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b26225c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "attribute_cols = [\n",
    "    'Site Use Attribute 1', 'Site Use Attribute 2', \n",
    "    'Site Use Attribute 3', 'Site Use Attribute 6', \n",
    "    'Site Use Attribute 7', 'Site Use Attribute 9',\n",
    "    'Site Use Attribute 10'\n",
    "]\n",
    " \n",
    "final_clusters = {}\n",
    " \n",
    "for label, indices in clusters.items():\n",
    "    if len(indices) < 2:\n",
    "        continue\n",
    " \n",
    "    cluster_df = df.iloc[indices]\n",
    "    site_ids = cluster_df['Site ID'].tolist()\n",
    "\n",
    "    # --- Elimination Condition 1 ---\n",
    "    # Eliminate if addresses are 100% similar AND all Site IDs are distinct \n",
    "    # AND the combined attributes are all distinct.\n",
    "    # Check for 100% address similarity (i.e., all normalized addresses are identical)\n",
    "    address_strings = [full_rows[i] for i in indices]\n",
    "    if len(set(address_strings)) == 1:\n",
    "        are_site_ids_distinct = len(set(site_ids)) == len(site_ids)\n",
    "        attribute_values = cluster_df[attribute_cols].fillna('').astype(str).agg(' '.join, axis=1).tolist()\n",
    "        are_attributes_distinct = len(set(attribute_values)) == len(attribute_values)\n",
    " \n",
    "        if are_site_ids_distinct and are_attributes_distinct:\n",
    "            continue\n",
    " \n",
    "    final_clusters[label] = indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f81f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# start with your initial final_clusters\n",
    "current = final_clusters.copy()\n",
    "\n",
    "def find_medoid(indices):\n",
    "    sim_matrix = util.cos_sim(embs[indices], embs[indices])\n",
    "    sim_sums = sim_matrix.sum(dim=1).cpu().numpy()\n",
    "    return indices[int(np.argmax(sim_sums))]\n",
    "\n",
    "for it in range(iterations):\n",
    "    next_level = {}\n",
    "    for cid, indices in current.items():\n",
    "        if len(indices) < 2:\n",
    "            continue\n",
    "        med   = find_medoid(indices)\n",
    "        emb_m = embs[med]\n",
    "        sims_all = [float(cos_sim(emb_m, embs[i]))*100 for i in indices]\n",
    "        # exclude medoid from average\n",
    "        sims = [s for idx,s in zip(indices, sims_all) if idx != med]\n",
    "        avg_sim = sum(sims) / len(sims)\n",
    "        if avg_sim < avg_threshold:\n",
    "            # recluster this clusterâ€™s indices\n",
    "            X      = embs[indices].cpu().numpy()\n",
    "            labels = DBSCAN(eps=0.05, min_samples=2, metric='cosine').fit_predict(X)\n",
    "            for sub in set(labels):\n",
    "                if sub == -1: continue\n",
    "                key = f\"{cid}.{sub}\"\n",
    "                next_level[key] = [indices[i] for i,l in enumerate(labels) if l==sub]\n",
    "        else:\n",
    "            next_level[str(cid)] = indices\n",
    "    current = next_level\n",
    "\n",
    "final_clusters = current"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f1e13d34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Excel report saved to: content/ClusterReport.xlsx\n"
     ]
    }
   ],
   "source": [
    "# write out with sequential numbering\n",
    "wb  = Workbook()\n",
    "ws  = wb.active\n",
    "bold = Font(bold=True)\n",
    "rp   = 1\n",
    "\n",
    "output_xlsx = \"content/ClusterReport.xlsx\"\n",
    "\n",
    "items = sorted(final_clusters.items(), key=lambda x: x[0])\n",
    "for seq, (_, indices) in enumerate(items, start=1):\n",
    "    if len(indices) < 2:\n",
    "        continue\n",
    "    med   = find_medoid(indices)\n",
    "    emb_m = embs[med]\n",
    "    sims_all = [float(cos_sim(emb_m, embs[i]))*100 for i in indices]\n",
    "    sims = [s for idx,s in zip(indices, sims_all) if idx != med]\n",
    "    avg_sim = round(sum(sims)/len(sims),2)\n",
    "\n",
    "    ws.cell(rp,1,f\"Cluster {seq} (Avg {avg_sim}%):\").font = bold; rp+=1\n",
    "    ws.cell(rp,1,\"Similarity %\").font = bold\n",
    "    for ci,col in enumerate(report_cols, start=2):\n",
    "        ws.cell(rp,ci,col).font = bold\n",
    "    rp+=1\n",
    "\n",
    "    for idx,sim in zip(sorted(indices), sims_all):\n",
    "        ws.cell(rp,1,f\"{round(sim,2)}%\")\n",
    "        for ci,col in enumerate(report_cols, start=2):\n",
    "            ws.cell(rp,ci,df.iloc[idx][col])\n",
    "        rp+=1\n",
    "    rp+=1\n",
    "\n",
    "wb.save(output_xlsx)\n",
    "print(f\"\\nExcel report saved to: {output_xlsx}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
