{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c051b987",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import json\n",
    "from collections import defaultdict\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import warnings\n",
    "import xlsxwriter\n",
    "import numpy as np\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5f6d94c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "address_similarity_threshold = 75\n",
    "\n",
    "classification_path = \"content/YEU_CustomerClusterReport.xlsx\"\n",
    "site_path = \"content/YEU_Preprocessed.xlsx\"\n",
    "site_sheet_name = \"Sheet1\"\n",
    "output_path = \"content/YEU_FinalReport.xlsx\"\n",
    "address_cluster_path = \"content/YEU_AddressClusterReport.xlsx\"\n",
    "\n",
    "classification_df = pd.read_excel(classification_path)\n",
    "df_sites = pd.read_excel(site_path, site_sheet_name)\n",
    "\n",
    "address_cols = ['Address', 'City', 'Postal Code', 'State', 'Country']\n",
    "\n",
    "report_cols = [\n",
    "    'Name', 'Purpose', 'Customer ID'\n",
    "] + address_cols\n",
    "\n",
    "columns_to_keep = [\n",
    "    'classification', 'Customer Name', 'Customer ID', 'Name'\n",
    "] + address_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d721174b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sites = df_sites[report_cols]\n",
    "merged_df = classification_df.merge(df_sites, on='Customer ID', how='inner').fillna(\"\")\n",
    "\n",
    "def normalize_text(s):\n",
    "    return re.sub(r\"\\s+\", \" \", re.sub(r\"[^\\w\\s]\", \" \", str(s).lower())).strip()\n",
    "\n",
    "def build_weighted_text(row):\n",
    "    parts = []\n",
    "    for col in address_cols:\n",
    "        val = str(row.get(col, '')).strip()\n",
    "        if col == \"Postal Code\" and \"-\" in val:\n",
    "            val = val.split(\"-\")[0].strip()\n",
    "        parts.append((val + \" \") * 3 if col in [\"Address\", \"Postal Code\"] else val)\n",
    "    return normalize_text(\" \".join(parts))\n",
    "\n",
    "merged_df[\"full_address\"] = merged_df.apply(build_weighted_text, axis=1)\n",
    "\n",
    "merged_df = merged_df.drop_duplicates()\n",
    "\n",
    "merged_df = merged_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1348b385",
   "metadata": {},
   "outputs": [],
   "source": [
    "sbert = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "embs = sbert.encode(\n",
    "    merged_df[\"full_address\"].tolist(),\n",
    "    convert_to_tensor=False,\n",
    "    normalize_embeddings=True\n",
    ")\n",
    "embs = np.array(embs)\n",
    "\n",
    "sim_matrix = cosine_similarity(embs)\n",
    "\n",
    "customer_ids = merged_df[\"Customer ID\"].astype(str).values\n",
    "site_names = merged_df[\"Name\"].astype(str).values\n",
    "\n",
    "similarity_column = []\n",
    "n_rows = len(merged_df)\n",
    "\n",
    "for i in range(n_rows):\n",
    "    pid1 = customer_ids[i]\n",
    "    sims = []\n",
    "    \n",
    "    mask = (customer_ids != pid1)\n",
    "    \n",
    "    valid_indices = np.where(mask)[0]\n",
    "    \n",
    "    for j in valid_indices:\n",
    "        sims.append({\n",
    "            \"To Party\": customer_ids[j],\n",
    "            \"To Site\": site_names[j],\n",
    "            \"Similarity\": f\"{sim_matrix[i, j] * 100:.2f}%\"\n",
    "        })\n",
    "    \n",
    "    similarity_column.append(json.dumps(sims, ensure_ascii=False))\n",
    "\n",
    "merged_df[\"Similarity to Other Parties\"] = similarity_column\n",
    "merged_df[\"Similarity Parsed\"] = merged_df[\"Similarity to Other Parties\"].apply(json.loads)\n",
    "merged_df.to_excel(\"content/YEU_merged_Cluster.xlsx\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c2624982",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_clusters = []\n",
    "\n",
    "for class_id, group in merged_df.groupby(\"classification\"):\n",
    "    pids_in_class = set(group[\"Customer ID\"])\n",
    "\n",
    "    qualified_rows = []\n",
    "    for _, row in group.iterrows():\n",
    "        sims = row[\"Similarity Parsed\"]\n",
    "        for entry in sims:\n",
    "            if float(entry[\"Similarity\"].replace('%', '')) > address_similarity_threshold and entry[\"To Party\"] in pids_in_class:\n",
    "                qualified_rows.append(row)\n",
    "                break\n",
    "\n",
    "    if len(qualified_rows) >= 2:\n",
    "        final_clusters.append(pd.DataFrame(qualified_rows))\n",
    "\n",
    "if final_clusters:\n",
    "    result_df = pd.concat(final_clusters).copy()\n",
    "    result_df.sort_values(by=[\"classification\", \"Customer ID\"], inplace=True)\n",
    "    old_to_new_class = {old: new for new, old in enumerate(sorted(result_df[\"classification\"].unique()), start=1)}\n",
    "    result_df[\"classification\"] = result_df[\"classification\"].map(old_to_new_class)\n",
    "else:\n",
    "    result_df = pd.DataFrame(columns=merged_df.columns)\n",
    "\n",
    "type_labels_map = {}\n",
    "\n",
    "for class_id, group in result_df.groupby(\"classification\"):\n",
    "    is_pure_customer_duplication = True\n",
    "\n",
    "    for sims in group[\"Similarity to Other Parties\"]:\n",
    "        parsed = json.loads(sims)\n",
    "        sims_floats = [float(entry[\"Similarity\"].replace('%', '')) for entry in parsed]\n",
    "\n",
    "        if 100.0 not in sims_floats:\n",
    "            is_pure_customer_duplication = False\n",
    "            break\n",
    "\n",
    "        if any(sim != 100.0 for sim in sims_floats):\n",
    "            is_pure_customer_duplication = False\n",
    "            break\n",
    "\n",
    "    label = \"Customer Duplication\" if is_pure_customer_duplication else \"Customer + Address Duplication\"\n",
    "    type_labels_map[class_id] = label\n",
    "\n",
    "result_df[\"type\"] = result_df[\"classification\"].map(type_labels_map)\n",
    "result_df = result_df[[\"type\"] + columns_to_keep]\n",
    "\n",
    "result_df.drop(columns=[\"Similarity Parsed\", \"full_address\", \"row_id\"], errors='ignore', inplace=True)\n",
    "result_df = result_df[[\"type\"] + columns_to_keep]\n",
    "\n",
    "addr_dup_df = pd.read_excel(address_cluster_path)\n",
    "addr_dup_df[\"type\"] = \"Address Duplication\"\n",
    "final_df = pd.concat([result_df, addr_dup_df], ignore_index=True)\n",
    "\n",
    "final_df = final_df.replace([np.inf, -np.inf], np.nan)\n",
    "final_df = final_df.fillna(\"\")\n",
    "\n",
    "final_df = final_df[[\"type\"] + columns_to_keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f12e8a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.ExcelWriter(output_path, engine='xlsxwriter') as writer:\n",
    "    final_df.to_excel(writer, index=False, sheet_name='Filtered')\n",
    "    \n",
    "    workbook = writer.book\n",
    "    worksheet = writer.sheets['Filtered']\n",
    "\n",
    "    header_format = workbook.add_format({\n",
    "        'bold': True,\n",
    "        'bg_color': '#D3D3D3',\n",
    "        'border': 1\n",
    "    })\n",
    "\n",
    "    border_format = workbook.add_format({'border': 1})\n",
    "    highlight_format = workbook.add_format({'bg_color': '#FFFACD', 'border': 1})\n",
    "\n",
    "    for col_num, column_name in enumerate(final_df.columns):\n",
    "        worksheet.write(0, col_num, column_name, header_format)\n",
    "\n",
    "    worksheet.autofilter(0, 0, 0, len(final_df.columns) - 1)\n",
    "\n",
    "    max_row = final_df.shape[0]\n",
    "    max_col = final_df.shape[1]\n",
    "\n",
    "    address_col_indices = [final_df.columns.get_loc(col) for col in address_cols + [\"Customer ID\", \"Customer Name\"] if col in final_df.columns]\n",
    "\n",
    "    for class_id, group in final_df.groupby('classification'):\n",
    "        cluster_indices = group.index.tolist()\n",
    "        for col_idx in address_col_indices:\n",
    "            col_name = final_df.columns[col_idx]\n",
    "            mode_val = group[col_name].mode().iloc[0] if not group[col_name].mode().empty else None\n",
    "            highlight_entire_col = any(\n",
    "                mode_val is not None and cell_val != mode_val\n",
    "                for cell_val in group[col_name]\n",
    "            )\n",
    "            for row_idx in cluster_indices:\n",
    "                excel_row = row_idx + 1\n",
    "                cell_val = final_df.iloc[row_idx, col_idx]\n",
    "                if highlight_entire_col:\n",
    "                    worksheet.write(excel_row, col_idx, cell_val, highlight_format)\n",
    "                else:\n",
    "                    worksheet.write(excel_row, col_idx, cell_val, border_format)\n",
    "        for row_idx in cluster_indices:\n",
    "            for col in range(max_col):\n",
    "                if col not in address_col_indices:\n",
    "                    excel_row = row_idx + 1\n",
    "                    worksheet.write(excel_row, col, final_df.iloc[row_idx, col], border_format)\n",
    "\n",
    "    for idx, col in enumerate(final_df.columns):\n",
    "        col_data = final_df[col].astype(str)\n",
    "        max_len = max([len(str(col))] + col_data.map(len).tolist())\n",
    "        worksheet.set_column(idx, idx, max_len + 2)\n",
    "\n",
    "output_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a11076a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.ExcelWriter(output_path, engine='xlsxwriter') as writer:\n",
    "    for dup_type, type_group in final_df.groupby(\"type\"):\n",
    "        df_to_write = type_group.drop(columns=[\"type\"])\n",
    "\n",
    "        df_to_write.to_excel(writer, index=False, sheet_name=dup_type[:31]) \n",
    "\n",
    "        workbook = writer.book\n",
    "        worksheet = writer.sheets[dup_type[:31]]\n",
    "\n",
    "        header_format = workbook.add_format({\n",
    "            'bold': True,\n",
    "            'bg_color': '#D3D3D3',\n",
    "            'border': 1\n",
    "        })\n",
    "        border_format = workbook.add_format({'border': 1})\n",
    "        address_highlight_format = workbook.add_format({'bg_color': '#FFFACD', 'border': 1})  # light yellow\n",
    "        customer_highlight_format = workbook.add_format({'bg_color': '#ADD8E6', 'border': 1})  # light blue\n",
    "\n",
    "        for col_num, column_name in enumerate(df_to_write.columns):\n",
    "            worksheet.write(0, col_num, column_name, header_format)\n",
    "\n",
    "        worksheet.autofilter(0, 0, 0, len(df_to_write.columns) - 1)\n",
    "\n",
    "        max_col = df_to_write.shape[1]\n",
    "\n",
    "        address_col_indices = [df_to_write.columns.get_loc(col) for col in address_cols if col in df_to_write.columns]\n",
    "        customer_col_indices = [df_to_write.columns.get_loc(col) for col in [\"Customer ID\", \"Customer Name\"] if col in df_to_write.columns]\n",
    "\n",
    "        for class_id, group in df_to_write.groupby('classification'):\n",
    "            cluster_positions = [df_to_write.index.get_loc(idx) for idx in group.index]\n",
    "\n",
    "            if dup_type in [\"Address Duplication\", \"Customer + Address Duplication\"]:\n",
    "                for col_idx in address_col_indices:\n",
    "                    col_name = df_to_write.columns[col_idx]\n",
    "                    mode_val = group[col_name].mode().iloc[0] if not group[col_name].mode().empty else None\n",
    "                    for pos in cluster_positions:\n",
    "                        excel_row = pos + 1\n",
    "                        cell_val = df_to_write.iloc[pos, col_idx]\n",
    "                        if mode_val is not None and cell_val != mode_val:\n",
    "                            worksheet.write(excel_row, col_idx, cell_val, address_highlight_format)\n",
    "                        else:\n",
    "                            worksheet.write(excel_row, col_idx, cell_val, border_format)\n",
    "\n",
    "            if dup_type in [\"Customer Duplication\", \"Customer + Address Duplication\"]:\n",
    "                for col_idx in customer_col_indices:\n",
    "                    col_name = df_to_write.columns[col_idx]\n",
    "                    mode_val = group[col_name].mode().iloc[0] if not group[col_name].mode().empty else None\n",
    "                    for pos in cluster_positions:\n",
    "                        excel_row = pos + 1\n",
    "                        cell_val = df_to_write.iloc[pos, col_idx]\n",
    "                        if mode_val is not None and cell_val != mode_val:\n",
    "                            worksheet.write(excel_row, col_idx, cell_val, customer_highlight_format)\n",
    "                        else:\n",
    "                            worksheet.write(excel_row, col_idx, cell_val, border_format)\n",
    "\n",
    "            for pos in cluster_positions:\n",
    "                for col in range(max_col):\n",
    "                    if col not in address_col_indices and col not in customer_col_indices:\n",
    "                        excel_row = pos + 1\n",
    "                        worksheet.write(excel_row, col, df_to_write.iloc[pos, col], border_format)\n",
    "\n",
    "        for idx, col in enumerate(df_to_write.columns):\n",
    "            col_data = df_to_write[col].astype(str)\n",
    "            max_len = max([len(str(col))] + col_data.map(len).tolist())\n",
    "            worksheet.set_column(idx, idx, max_len + 2)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
