{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b2e4e6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted address-related columns: ['Full Address', 'City Name', 'State Region', 'Postal Code', 'Country Name']\n",
      "['Full Address', 'City Name', 'State Region', 'Postal Code', 'Country Name']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from rapidfuzz import fuzz\n",
    "from docx import Document\n",
    "from collections import defaultdict\n",
    "import google.generativeai as genai\n",
    "import json\n",
    "import ast\n",
    "\n",
    "input_path = \"Site and.xlsx\"\n",
    "df = pd.read_excel(input_path)\n",
    "\n",
    "genai.configure(api_key=\"AIzaSyAMrzeuCtgCF5l_8o5Q4HCf6cSy_VudVXc\")\n",
    "model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
    "\n",
    "template_df = pd.read_excel(input_path, header=None)\n",
    "all_columns = template_df.iloc[0].tolist()\n",
    "\n",
    "prompt = f\"\"\"\n",
    "You are a data expert. Your task is to identify columns related to addresses from a list of column names.\n",
    "\n",
    "Given the following list of column names:\n",
    "{all_columns}\n",
    "\n",
    "Return only the column names that are related to address information (like street, area, city, state, zip code, postal code, location, etc.).\n",
    "\n",
    "Only return a valid Python list of strings. Do not include any explanation or extra text.\n",
    "\n",
    "Example output:\n",
    "[\"Street Address\", \"City\", \"Zip\", \"State\", \"Pincode\"]\n",
    "\"\"\"\n",
    "\n",
    "response = model.generate_content(prompt)\n",
    "\n",
    "try:\n",
    "    text = response.text.strip()\n",
    "    address_columns = ast.literal_eval(text)\n",
    "except (SyntaxError, ValueError) as e:\n",
    "    print(\"Error parsing response to list:\", e)\n",
    "    address_columns = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "520464f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.system(\"python -m spacy download en_core_web_sm\")\n",
    "sbert = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def normalize_text(s):\n",
    "    s = str(s).lower()\n",
    "    s = re.sub(r\"[^\\w\\s]\", \" \", s)\n",
    "    return re.sub(r\"\\s+\", \" \", s).strip()\n",
    "\n",
    "full_rows = (\n",
    "    df[address_cols]\n",
    "    .fillna(\"\")\n",
    "    .astype(str)\n",
    "    .agg(\" \".join, axis=1)\n",
    "    .map(normalize_text)\n",
    "    .tolist()\n",
    ")\n",
    "\n",
    "embs = sbert.encode(full_rows, convert_to_tensor=True, normalize_embeddings=True)\n",
    "matrix = embs.cpu().numpy()\n",
    "\n",
    "cl = DBSCAN(eps=0.15, min_samples=2, metric='cosine').fit(matrix)\n",
    "clusters = defaultdict(list)\n",
    "for idx, label in enumerate(cl.labels_):\n",
    "    if label != -1:\n",
    "        clusters[label].append(idx)\n",
    "\n",
    "def extract_canonical_gpe(text):\n",
    "    doc = nlp(text)\n",
    "    gpes = [ent.text.strip().lower() for ent in doc.ents if ent.label_ == \"GPE\"]\n",
    "    canonicals = []\n",
    "    for gpe in gpes:\n",
    "        try:\n",
    "            country = pycountry.countries.lookup(gpe)\n",
    "            canonicals.append(country.name.lower())\n",
    "        except:\n",
    "            canonicals.append(gpe)\n",
    "    if canonicals:\n",
    "        return max(set(canonicals), key=canonicals.count)\n",
    "    return \"\"\n",
    "\n",
    "canonical_gpes = [extract_canonical_gpe(row) for row in full_rows]\n",
    "\n",
    "filtered = []\n",
    "for label, indices in clusters.items():\n",
    "    gpe_map = defaultdict(list)\n",
    "    for i in indices:\n",
    "        gpe_map[canonical_gpes[i]].append(i)\n",
    "    for gpe_group in gpe_map.values():\n",
    "        if len(gpe_group) > 1:\n",
    "            filtered.append(sorted(set(gpe_group)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8229ab07",
   "metadata": {},
   "outputs": [],
   "source": [
    "similar_rows_map = defaultdict(list)\n",
    "for group in filtered:\n",
    "    for i in group:\n",
    "        similar_rows_map[i] = group\n",
    "\n",
    "similar_excel_row_map = {}\n",
    "for idx, group in similar_rows_map.items():\n",
    "    excel_rows = sorted([(i + header_row_num + 2) for i in group])\n",
    "    similar_excel_row_map[idx] = \", \".join(map(str, excel_rows))\n",
    "\n",
    "df[\"Similar Rows\"] = df.index.map(lambda i: similar_excel_row_map.get(i, \"\"))\n",
    "\n",
    "final_output_path = \"content/Similarity_report.xlsx\"\n",
    "df.to_excel(final_output_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8283e31a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Address Line 1',\n",
       " 'Address Line 2',\n",
       " 'Mail Stop',\n",
       " 'City',\n",
       " 'State/Province',\n",
       " 'Postal Code',\n",
       " 'County',\n",
       " 'Country']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from rapidfuzz import fuzz\n",
    "from docx import Document\n",
    "from collections import defaultdict\n",
    "import google.generativeai as genai\n",
    "import ast\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from sklearn.cluster import DBSCAN\n",
    "import numpy as np\n",
    "import pycountry\n",
    "import spacy\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "import openpyxl\n",
    "from openpyxl.styles import Font\n",
    "from openpyxl.utils.dataframe import dataframe_to_rows\n",
    "from openpyxl import Workbook\n",
    "\n",
    "input_path = \"content/Site and Site Uses.xlsx\"\n",
    "module = \"absolute address\"\n",
    "sheet_name = \"Sheet1\"\n",
    "header_row_num = 0\n",
    "# group_by = [\"Account ID\"]\n",
    "group_by = []\n",
    "\n",
    "genai.configure(api_key=\"AIzaSyA5NWnp7qoQMoTQZMi8cWlS0Ei8-_SDvLs\")\n",
    "model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
    "\n",
    "df = pd.read_excel(input_path, sheet_name)\n",
    "all_columns = pd.read_excel(input_path, sheet_name, header=None).iloc[header_row_num].tolist()\n",
    "\n",
    "prompt = f\"\"\"\n",
    "You are a data expert. Your task is to identify ONLY DISTINGUIHING columns related to module: {module} from a list of column names.\n",
    "\n",
    "Given the following list of column names:\n",
    "{all_columns}\n",
    "\n",
    "Only return a valid Python list of strings. Dont include IDs and Attributes and Timezone. Do not include any explanation or extra text.\n",
    "\n",
    "Example output:\n",
    "[\"DISTINGUIHING module related Column A\", \"module related Column B\", \"module related Column C\", ...]\n",
    "\"\"\"\n",
    "\n",
    "response = model.generate_content(prompt)\n",
    "\n",
    "try:\n",
    "    text = response.text.strip()\n",
    "    address_cols = ast.literal_eval(text)\n",
    "except (SyntaxError, ValueError) as e:\n",
    "    print(\"Error parsing response to list:\", e)\n",
    "    address_cols = []\n",
    "\n",
    "address_cols"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
