{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02cc4276",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pandas rapidfuzz python-docx recordlinkage google-generativeai sentence-transformers scikit-learn numpy pycountry spacy openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e279a890",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from rapidfuzz import fuzz\n",
    "from docx import Document\n",
    "from collections import defaultdict\n",
    "import google.generativeai as genai\n",
    "import ast\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from sklearn.cluster import DBSCAN\n",
    "import numpy as np\n",
    "import pycountry\n",
    "import spacy\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "import openpyxl\n",
    "from openpyxl.styles import Font\n",
    "from openpyxl.utils.dataframe import dataframe_to_rows\n",
    "from openpyxl import Workbook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "131894c2",
   "metadata": {},
   "source": [
    "### Input parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b4c34d",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = \"content/Site and Site Uses.xlsx\"\n",
    "module = \"absolute address\"\n",
    "sheet_name = \"Sheet1\"\n",
    "header_row_num = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca7a00ed",
   "metadata": {},
   "source": [
    "### Identify Module related columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2506169",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Address Line 1',\n",
       " 'Address Line 2',\n",
       " 'Mail Stop',\n",
       " 'City',\n",
       " 'State/Province',\n",
       " 'Postal Code',\n",
       " 'County',\n",
       " 'Country']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "genai.configure(api_key=\"AIzaSyA5NWnp7qoQMoTQZMi8cWlS0Ei8-_SDvLs\")\n",
    "model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
    "\n",
    "df = pd.read_excel(input_path, sheet_name)\n",
    "all_columns = pd.read_excel(input_path, sheet_name, header=None).iloc[header_row_num].tolist()\n",
    "\n",
    "prompt = f\"\"\"\n",
    "You are a data expert. Your task is to identify ONLY DISTINGUIHING columns related to module: {module} from a list of column names.\n",
    "\n",
    "Given the following list of column names:\n",
    "{all_columns}\n",
    "\n",
    "Only return a valid Python list of strings. Dont include IDs and Attributes and Timezone. Do not include any explanation or extra text.\n",
    "\n",
    "Example output:\n",
    "[\"DISTINGUIHING module related Column A\", \"module related Column B\", \"module related Column C\", ...]\n",
    "\"\"\"\n",
    "\n",
    "response = model.generate_content(prompt)\n",
    "\n",
    "try:\n",
    "    text = response.text.strip()\n",
    "    address_cols = ast.literal_eval(text)\n",
    "except (SyntaxError, ValueError) as e:\n",
    "    print(\"Error parsing response to list:\", e)\n",
    "    address_cols = []\n",
    "\n",
    "address_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4d3988c",
   "metadata": {},
   "source": [
    "### Vectorization and Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19e4409e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mos\u001b[49m.system(\u001b[33m\"\u001b[39m\u001b[33mpython -m spacy download en_core_web_sm\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      2\u001b[39m sbert = SentenceTransformer(\u001b[33m'\u001b[39m\u001b[33mall-MiniLM-L6-v2\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      3\u001b[39m nlp = spacy.load(\u001b[33m\"\u001b[39m\u001b[33men_core_web_sm\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "os.system(\"python -m spacy download en_core_web_sm\")\n",
    "sbert = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def normalize_text(s):\n",
    "    s = str(s).lower()\n",
    "    s = re.sub(r\"[^\\w\\s]\", \" \", s)\n",
    "    return re.sub(r\"\\s+\", \" \", s).strip()\n",
    "\n",
    "full_rows = (\n",
    "    df[address_cols]\n",
    "    .fillna(\"\")\n",
    "    .astype(str)\n",
    "    .agg(\" \".join, axis=1)\n",
    "    .map(normalize_text)\n",
    "    .tolist()\n",
    ")\n",
    "\n",
    "embs = sbert.encode(full_rows, convert_to_tensor=True, normalize_embeddings=True)\n",
    "matrix = embs.cpu().numpy()\n",
    "\n",
    "cl = DBSCAN(eps=0.05, min_samples=2, metric='cosine').fit(matrix)\n",
    "clusters = defaultdict(list)\n",
    "for idx, label in enumerate(cl.labels_):\n",
    "    if label != -1:\n",
    "        clusters[label].append(idx)\n",
    "\n",
    "def extract_canonical_gpe(text):\n",
    "    doc = nlp(text)\n",
    "    gpes = [ent.text.strip().lower() for ent in doc.ents if ent.label_ == \"GPE\"]\n",
    "    canonicals = []\n",
    "    for gpe in gpes:\n",
    "        try:\n",
    "            country = pycountry.countries.lookup(gpe)\n",
    "            canonicals.append(country.name.lower())\n",
    "        except:\n",
    "            canonicals.append(gpe)\n",
    "    if canonicals:\n",
    "        return max(set(canonicals), key=canonicals.count)\n",
    "    return \"\"\n",
    "\n",
    "canonical_gpes = [extract_canonical_gpe(row) for row in full_rows]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a071d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying business rules...\n"
     ]
    }
   ],
   "source": [
    "attribute_cols = [\n",
    "    'Site Use Attribute 1', 'Site Use Attribute 2', 'Site Use Attribute 3',\n",
    "    'Site Use Attribute 6', 'Site Use Attribute 7', 'Site Use Attribute 9',\n",
    "    'Site Use Attribute 10', 'Site Use Attribute 12'\n",
    "]\n",
    " \n",
    "final_clusters = {}\n",
    " \n",
    "for label, indices in clusters.items():\n",
    "    if len(indices) < 2:\n",
    "        continue\n",
    " \n",
    "    cluster_df = df.iloc[indices]\n",
    "    site_ids = cluster_df['Site ID'].tolist()\n",
    "    site_use_ids = cluster_df['Site Use ID'].tolist()\n",
    "    # --- Elimination Condition 1 ---\n",
    "    # Eliminate if all Site IDs are the same BUT all Site Use IDs are different.\n",
    "    if len(set(site_ids)) == 1 and len(set(site_use_ids)) == len(site_use_ids):\n",
    "        continue\n",
    "\n",
    "    # --- Elimination Condition 2 ---\n",
    "    # Eliminate if addresses are 100% similar AND all Site IDs are distinct \n",
    "    # AND the combined attributes are all distinct.\n",
    "    # Check for 100% address similarity (i.e., all normalized addresses are identical)\n",
    "    address_strings = [full_rows[i] for i in indices]\n",
    "    if len(set(address_strings)) == 1:\n",
    "        are_site_ids_distinct = len(set(site_ids)) == len(site_ids)\n",
    "        attribute_values = cluster_df[attribute_cols].fillna('').astype(str).agg(' '.join, axis=1).tolist()\n",
    "        are_attributes_distinct = len(set(attribute_values)) == len(attribute_values)\n",
    " \n",
    "        if are_site_ids_distinct and are_attributes_distinct:\n",
    "            continue\n",
    " \n",
    "    final_clusters[label] = indices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cad83bf",
   "metadata": {},
   "source": [
    "### Excel Repot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "399c7513",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Excel report saved to: content/Cluster_Report.xlsx\n"
     ]
    }
   ],
   "source": [
    "wb = Workbook()\n",
    "ws = wb.active\n",
    "ws.title = \"Cluster Report\"\n",
    "\n",
    "bold_font = Font(bold=True)\n",
    "row_pointer = 1\n",
    "\n",
    "# Sequentially number the clusters regardless of original label\n",
    "for new_cluster_id, (_, indices) in enumerate(sorted(final_clusters.items()), start=1):\n",
    "    if len(indices) < 2:\n",
    "        continue\n",
    "\n",
    "    ws.cell(row=row_pointer, column=1, value=f\"Cluster {new_cluster_id}:\").font = bold_font\n",
    "    row_pointer += 1\n",
    "\n",
    "    for col_index, col_name in enumerate(df.columns, start=1):\n",
    "        ws.cell(row=row_pointer, column=col_index, value=col_name).font = bold_font\n",
    "    row_pointer += 1\n",
    "\n",
    "    for idx in sorted(indices):\n",
    "        for col_index, col_name in enumerate(df.columns, start=1):\n",
    "            ws.cell(row=row_pointer, column=col_index, value=df.iloc[idx][col_name])\n",
    "        row_pointer += 1\n",
    "\n",
    "    row_pointer += 1\n",
    "\n",
    "output_xlsx = \"content/Cluster_Report.xlsx\"\n",
    "wb.save(output_xlsx)\n",
    "print(f\"\\nExcel report saved to: {output_xlsx}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aef4b92",
   "metadata": {},
   "source": [
    "### Detailed word report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd8c083",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DOCX report saved to: content/redundancy_report.docx\n"
     ]
    }
   ],
   "source": [
    "def format_address_row(i):\n",
    "    return \", \".join(\n",
    "        f\"{col}='{df.at[i, col]}'\" for col in address_cols if str(df.at[i, col]).strip()\n",
    "    )\n",
    "\n",
    "def build_prompt(grp):\n",
    "    prompt = \"\"\"\n",
    "        Compare the fields in the following rows and return each and every and clear differences in the format like:\n",
    "        country in row 17 is \\\"USA\\\" and \\\"United States\\\" in row 18.\\n And Address 1 is \\\"xyz\\\" in row 17 and \\\"x.y.z\\\" in row 19.\\n And... so on\n",
    "        or\n",
    "        in row 17 \\\"USA\\\" is in column state along with the \\\"<state name>\\\". And... so on.\n",
    "        I there are multiple rows in a group then adjust accordingly like country in row 2 is \\\"something\\\" in row 3 and 4 is \\\"something else\\\" in row 5 is empty\n",
    "        Respond with only such lines and nothing else. You can list each and every the differences.\n",
    "    \"\"\"\n",
    "    for i in grp:\n",
    "        prompt += f\"Row {i+1}: {format_address_row(i)}\\n\"\n",
    "    return prompt\n",
    "\n",
    "doc = Document()\n",
    "doc.add_heading(\"Redundancy Report\", level=1)\n",
    "\n",
    "# for grp in filtered:\n",
    "#     prompt = build_prompt(grp)\n",
    "#     response = model.generate_content(prompt)\n",
    "#     explanation = response.text.strip()\n",
    "#     if explanation:\n",
    "#         doc.add_paragraph(explanation)\n",
    "\n",
    "prompt = build_prompt(filtered[0])\n",
    "response = model.generate_content(prompt)\n",
    "explanation = response.text.strip()\n",
    "if explanation:\n",
    "    doc.add_paragraph(explanation)\n",
    "\n",
    "output_docx = \"content/redundancy_report.docx\"\n",
    "doc.save(output_docx)\n",
    "print(f\"\\nDOCX report saved to: {output_docx}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
